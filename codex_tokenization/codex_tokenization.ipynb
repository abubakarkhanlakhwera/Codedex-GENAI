{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJXRG8r/koS1a1llweznGF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abubakarkhanlakhwera/Codedex-GENAI/blob/main/codex_tokenization/codex_tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66TCdV_56wBB",
        "outputId": "07831b28-7021-4b24-c6c2-2708a7bf4da3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EchZ4L-A53zX",
        "outputId": "a65c6e50-99f2-4043-cdfd-3169ec1525d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['iam', 'learning', 'generative', 'ai']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "sample_text = 'IAm learning Generative AI'\n",
        "tokens = nltk.word_tokenize(sample_text.lower())\n",
        "\n",
        "print('Tokens:',tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ngram**"
      ],
      "metadata": {
        "id": "djNK_GsX7t_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams"
      ],
      "metadata": {
        "id": "8J22GPhE6ltv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unigram**"
      ],
      "metadata": {
        "id": "hm4xhnKC810n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = 'I am learning NLP(Natural Language Processing)'\n",
        "tokens = nltk.word_tokenize(sample_text.lower())\n",
        "unigrams = list(ngrams(tokens,1))\n",
        "print(unigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGcAc8ID81hX",
        "outputId": "e1d901fb-3da4-4c5b-f682-5858519d6c58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('i',), ('am',), ('learning',), ('nlp',), ('(',), ('natural',), ('language',), ('processing',), (')',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bigrams**"
      ],
      "metadata": {
        "id": "rUVli6Ln8kSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'Iam learning AI'\n",
        "tokens = nltk.word_tokenize(sentence.lower())\n",
        "bigrams = list(ngrams(tokens,2))\n",
        "print(bigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP8QfURJ75jX",
        "outputId": "349c45f2-bc84-4488-af45-fc8bf2d42527"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('iam', 'learning'), ('learning', 'ai')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TriGrams**"
      ],
      "metadata": {
        "id": "OS1XrDeA9E-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = 'I am learning NLP(Natural Language Processing)'\n",
        "tokens = nltk.word_tokenize(sample_text.lower())\n",
        "trigrams = list(ngrams(tokens,3))\n",
        "print(trigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BThO5gL8Vt4",
        "outputId": "1e26d947-3335-48c3-e701-48a3643ec3bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('i', 'am', 'learning'), ('am', 'learning', 'nlp'), ('learning', 'nlp', '('), ('nlp', '(', 'natural'), ('(', 'natural', 'language'), ('natural', 'language', 'processing'), ('language', 'processing', ')')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CMsKiNjE9fb4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}